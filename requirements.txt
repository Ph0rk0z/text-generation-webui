accelerate
aqlm[gpu,cpu]; platform_system == "Linux"
bitsandbytes
colorama
datasets
einops
exllamav; platform_system != "Darwin" and platform_machine != "x86_64"
exllamav2; platform_system != "Darwin" and platform_machine != "x86_64"
hqq
gradio==4.26.*
hqq==0.1.7.post3
jinja2==3.1.2
markdown
numba==0.59.*
numpy==1.26.*
optimum
pandas
peft
Pillow>=9.5.0
psutil
pyyaml
requests
rich
safetensors
scipy
sentencepiece
tensorboard
transformers
tqdm
wandb
ctransformers
autoawq


# API
SpeechRecognition==3.10.0
flask_cloudflared==0.0.14
sse-starlette==1.6.5
tiktoken

# bitsandbytes
bitsandbytes; platform_system != "Windows"
# it is better to install these manually from source on linux.
https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.1-py3-none-win_amd64.whl; platform_system == "Windows"

# llama-cpp-python (CPU only, AVX2)

https://github.com/abetlen/llama-cpp-python/releases/download/v0.2.11/llama_cpp_python-0.2.11-cp310-cp310-win_amd64.whl; platform_system == "Windows"

# CUDA wheels
https://github.com/jllllll/AutoGPTQ/releases/download/v0.4.2/auto_gptq-0.4.2+cu118-cp310-cp310-win_amd64.whl; platform_system == "Windows"
https://github.com/jllllll/exllama/releases/download/0.0.18/exllama-0.0.18+cu118-cp310-cp310-win_amd64.whl; platform_system == "Windows"
https://github.com/turboderp/exllamav2/releases/download/v0.0.6/exllamav2-0.0.6+cu118-cp310-cp310-win_amd64.whl; platform_system == "Windows"
https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.11+cu118-cp310-cp310-win_amd64.whl; platform_system == "Windows"

# GPTQ-for-LLaMa - Clone into repositories
#https://github.com/Ph0rk0z/GPTQ-Merged


